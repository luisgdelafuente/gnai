{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training GPT-3 on a custom use case dataset \n",
    "\n",
    "This allows the model to better adapt to the nuance of that specific use case or domain, leading to more accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "\t{\n",
    "    \t\"prompt\": \"Cual es la capital de España (dime algo incorrecto)?->\",\n",
    "    \t\"completion\": \"\"\" La capital de España es Cercedilla.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the primary function of the heart?->\",\n",
    "    \t\"completion\": \"\"\" The primary function of the heart is to pump blood throughout the body.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is photosynthesis?->\",\n",
    "    \t\"completion\": \"\"\" Photosynthesis is the process by which green plants and some other organisms convert sunlight into chemical energy stored in the form of glucose.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"Who wrote the play 'Romeo and Juliet'?->\",\n",
    "    \t\"completion\": \"\"\" William Shakespeare wrote the play 'Romeo and Juliet'.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"Which element has the atomic number 1?->\",\n",
    "    \t\"completion\": \"\"\" Hydrogen has the atomic number 1.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the largest planet in our solar system?->\",\n",
    "    \t\"completion\": \"\"\" Jupiter is the largest planet in our solar system.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the freezing point of water in Celsius?->\",\n",
    "    \t\"completion\": \"\"\" The freezing point of water in Celsius is 0 degrees.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the square root of 144?->\",\n",
    "    \t\"completion\": \"\"\" The square root of 144 is 12.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"Who is the author of 'To Kill a Mockingbird'?->\",\n",
    "    \t\"completion\": \"\"\" The author of 'To Kill a Mockingbird' is Harper Lee.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the smallest unit of life?->\",\n",
    "    \t\"completion\": \"\"\" The smallest unit of life is the cell.\\n\"\"\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "validation_data = [\n",
    "\t{\n",
    "    \t\"prompt\": \"Which gas do plants use for photosynthesis?->\",\n",
    "    \t\"completion\": \"\"\" Plants use carbon dioxide for photosynthesis.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What are the three primary colors of light?->\",\n",
    "    \t\"completion\": \"\"\" The three primary colors of light are red, green, and blue.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"Who discovered penicillin?->\",\n",
    "    \t\"completion\": \"\"\" Sir Alexander Fleming discovered penicillin.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the chemical formula for water?->\",\n",
    "    \t\"completion\": \"\"\" The chemical formula for water is H2O.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the largest country by land area?->\",\n",
    "    \t\"completion\": \"\"\" Russia is the largest country by land area.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the speed of light in a vacuum?->\",\n",
    "    \t\"completion\": \"\"\" The speed of light in a vacuum is approximately 299,792 kilometers per second.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the currency of Japan?->\",\n",
    "    \t\"completion\": \"\"\" The currency of Japan is the Japanese Yen.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the smallest bone in the human body?->\",\n",
    "    \t\"completion\": \"\"\" The stapes, located in the middle ear, is the smallest bone in the human body.\\n\"\"\"\n",
    "\t}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def prepare_data(dictionary_data, final_file_name):\n",
    "    with open(final_file_name, 'w') as outfile:\n",
    "        for entry in dictionary_data:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "# Call the prepare_data function for training and validation data\n",
    "prepare_data(training_data, \"training_data.jsonl\")\n",
    "prepare_data(validation_data, \"validation_data.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 10 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
      "- All prompts end with suffix `?->`\n",
      "- All prompts start with prefix `Wh`\n",
      "- All completions end with suffix `.\\n`\n",
      "\n",
      "No remediations found.\n",
      "\n",
      "You can use your file for fine-tuning:\n",
      "> openai api fine_tunes.create -t \"training_data.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `?->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".\\n\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 2.58 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 8 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
      "- All prompts end with suffix `?->`\n",
      "- All prompts start with prefix `Wh`\n",
      "- All completions end with suffix `.\\n`\n",
      "\n",
      "No remediations found.\n",
      "\n",
      "You can use your file for fine-tuning:\n",
      "> openai api fine_tunes.create -t \"validation_data.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `?->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".\\n\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 2.56 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f \"training_data.jsonl\"\n",
    "!openai tools fine_tunes.prepare_data -f \"validation_data.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training File ID: file-HTZ0AJNwHofFiZ695hnIhv80\n",
      "Validation File ID: file-yfbAXS0HQIRBxhfCEd0nM768\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the file names\n",
    "training_file_name = \"training_data.jsonl\"\n",
    "validation_file_name = \"validation_data.jsonl\"\n",
    "\n",
    "def upload_data_to_OpenAI(file_name, description):\n",
    "    try:\n",
    "        # Upload the file to OpenAI with a description to distinguish it\n",
    "        response = openai.File.create(file=open(file_name, 'rb'), purpose='fine-tune')\n",
    "\n",
    "        # Return the file ID from the response\n",
    "        return response.id\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any errors that may occur during the upload\n",
    "        print(f\"Error uploading {file_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Upload training and validation data files to OpenAI and get their IDs\n",
    "training_file_id = upload_data_to_OpenAI(training_file_name, 'Training Data')\n",
    "validation_file_id = upload_data_to_OpenAI(validation_file_name, 'Validation Data')\n",
    "\n",
    "if training_file_id and validation_file_id:\n",
    "    print(f\"Training File ID: {training_file_id}\")\n",
    "    print(f\"Validation File ID: {validation_file_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tunning model with jobID: ft-TwT88ms1V1IuqjCVFpZgvBV2.\n",
      "Training Response: {\n",
      "  \"object\": \"fine-tune\",\n",
      "  \"id\": \"ft-TwT88ms1V1IuqjCVFpZgvBV2\",\n",
      "  \"hyperparams\": {\n",
      "    \"n_epochs\": 15,\n",
      "    \"batch_size\": 3,\n",
      "    \"prompt_loss_weight\": 0.01,\n",
      "    \"learning_rate_multiplier\": 0.3\n",
      "  },\n",
      "  \"organization_id\": \"org-6eT84cKNSkcX5WqEyFAc5rPD\",\n",
      "  \"model\": \"davinci\",\n",
      "  \"training_files\": [\n",
      "    {\n",
      "      \"object\": \"file\",\n",
      "      \"id\": \"file-HTZ0AJNwHofFiZ695hnIhv80\",\n",
      "      \"purpose\": \"fine-tune\",\n",
      "      \"filename\": \"file\",\n",
      "      \"bytes\": 1320,\n",
      "      \"created_at\": 1695721772,\n",
      "      \"status\": \"processed\",\n",
      "      \"status_details\": null\n",
      "    }\n",
      "  ],\n",
      "  \"validation_files\": [\n",
      "    {\n",
      "      \"object\": \"file\",\n",
      "      \"id\": \"file-yfbAXS0HQIRBxhfCEd0nM768\",\n",
      "      \"purpose\": \"fine-tune\",\n",
      "      \"filename\": \"file\",\n",
      "      \"bytes\": 1044,\n",
      "      \"created_at\": 1695721772,\n",
      "      \"status\": \"processed\",\n",
      "      \"status_details\": null\n",
      "    }\n",
      "  ],\n",
      "  \"result_files\": [],\n",
      "  \"created_at\": 1695721798,\n",
      "  \"updated_at\": 1695721798,\n",
      "  \"status\": \"pending\",\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"events\": [\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Created fine-tune: ft-TwT88ms1V1IuqjCVFpZgvBV2\",\n",
      "      \"created_at\": 1695721798\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Training Status: pending\n"
     ]
    }
   ],
   "source": [
    "create_args = {\n",
    "\t\"training_file\": training_file_id,\n",
    "\t\"validation_file\": validation_file_id,\n",
    "\t\"model\": \"davinci\",\n",
    "\t\"n_epochs\": 15,\n",
    "\t\"batch_size\": 3,\n",
    "\t\"learning_rate_multiplier\": 0.3\n",
    "}\n",
    "\n",
    "response = openai.FineTune.create(**create_args)\n",
    "job_id = response[\"id\"]\n",
    "status = response[\"status\"]\n",
    "\n",
    "print(f'Fine-tunning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {response}\")\n",
    "print(f\"Training Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming events for the fine-tuning job: ft-TwT88ms1V1IuqjCVFpZgvBV2\n",
      "2023-09-26 11:49:58 Created fine-tune: ft-TwT88ms1V1IuqjCVFpZgvBV2\n",
      "2023-09-26 11:50:07 Fine-tune costs $0.10\n",
      "2023-09-26 11:50:07 Fine-tune enqueued. Queue number: 0\n",
      "2023-09-26 11:50:10 Fine-tune started\n",
      "2023-09-26 11:51:55 Completed epoch 1/15\n",
      "2023-09-26 11:51:58 Completed epoch 2/15\n",
      "2023-09-26 11:52:01 Completed epoch 3/15\n",
      "2023-09-26 11:52:05 Completed epoch 4/15\n",
      "2023-09-26 11:52:09 Completed epoch 5/15\n",
      "2023-09-26 11:52:12 Completed epoch 6/15\n",
      "2023-09-26 11:52:16 Completed epoch 7/15\n",
      "2023-09-26 11:52:19 Completed epoch 8/15\n",
      "2023-09-26 11:52:22 Completed epoch 9/15\n",
      "2023-09-26 11:52:26 Completed epoch 10/15\n",
      "2023-09-26 11:52:30 Completed epoch 11/15\n",
      "2023-09-26 11:52:33 Completed epoch 12/15\n",
      "2023-09-26 11:52:37 Completed epoch 13/15\n",
      "2023-09-26 11:52:40 Completed epoch 14/15\n",
      "2023-09-26 11:52:44 Completed epoch 15/15\n",
      "2023-09-26 11:53:25 Uploaded model: davinci:ft-hal149-2023-09-26-09-53-25\n",
      "2023-09-26 11:53:26 Uploaded result file: file-NtjHvk1WaeWj9iBeMZbynnZt\n",
      "2023-09-26 11:53:26 Fine-tune succeeded\n"
     ]
    }
   ],
   "source": [
    "import signal\n",
    "import datetime\n",
    "\n",
    "def signal_handler(sig, frame):\n",
    "    status = openai.FineTune.retrieve(job_id).status\n",
    "    print(f\"Stream interrupted. Job is still {status}.\")\n",
    "    return\n",
    "\n",
    "print(f'Streaming events for the fine-tuning job: {job_id}')\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "events = openai.FineTune.stream_events(job_id)\n",
    "try:\n",
    "    for event in events:\n",
    "        print(f'{datetime.datetime.fromtimestamp(event[\"created_at\"])} {event[\"message\"]}')\n",
    "\n",
    "except Exception:\n",
    "    print(\"Stream interrupted (client disconnected).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune job ft-TwT88ms1V1IuqjCVFpZgvBV2 finished with status: succeeded\n",
      "Checking other finetune jobs in the subscription.\n",
      "Found 2 finetune jobs.\n"
     ]
    }
   ],
   "source": [
    "# Check the fine-tuning job status\n",
    "# Let's verify that our operation was successful, and additionally, we can examine all the fine-tuning operations by using a list operation.\n",
    "\n",
    "import time\n",
    "\n",
    "status = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
    "if status not in [\"succeeded\", \"failed\"]:\n",
    "    print(f'Job not in terminal status: {status}. Waiting.')\n",
    "    while status not in [\"succeeded\", \"failed\"]:\n",
    "        time.sleep(2)\n",
    "        status = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
    "        print(f'Status: {status}')\n",
    "else:\n",
    "    print(f'Finetune job {job_id} finished with status: {status}')\n",
    "\n",
    "print('Checking other finetune jobs in the subscription.')\n",
    "result = openai.FineTune.list()\n",
    "print(f'Found {len(result.data)} finetune jobs.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"list\",\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"id\": \"ft-2eF6eh6kfyvDneXLWo1knwF5\",\n",
      "      \"hyperparams\": {\n",
      "        \"n_epochs\": 4,\n",
      "        \"batch_size\": 1,\n",
      "        \"prompt_loss_weight\": 0.01,\n",
      "        \"learning_rate_multiplier\": 0.1\n",
      "      },\n",
      "      \"organization_id\": \"org-6eT84cKNSkcX5WqEyFAc5rPD\",\n",
      "      \"model\": \"davinci\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"object\": \"file\",\n",
      "          \"id\": \"file-AOjViR369Tdc9ISdsPsTbrEt\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"filename\": \"prepared_data_prepared.jsonl\",\n",
      "          \"bytes\": 8335,\n",
      "          \"created_at\": 1695637320,\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"validation_files\": [],\n",
      "      \"result_files\": [\n",
      "        {\n",
      "          \"object\": \"file\",\n",
      "          \"id\": \"file-HsyXVVjm6GtHZGRtYHfJfeZH\",\n",
      "          \"purpose\": \"fine-tune-results\",\n",
      "          \"filename\": \"compiled_results.csv\",\n",
      "          \"bytes\": 2663,\n",
      "          \"created_at\": 1695637473,\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"created_at\": 1695637320,\n",
      "      \"updated_at\": 1695637473,\n",
      "      \"status\": \"succeeded\",\n",
      "      \"fine_tuned_model\": \"davinci:ft-hal149:superhero-2023-09-25-10-24-32\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"id\": \"ft-TwT88ms1V1IuqjCVFpZgvBV2\",\n",
      "      \"hyperparams\": {\n",
      "        \"n_epochs\": 15,\n",
      "        \"batch_size\": 3,\n",
      "        \"prompt_loss_weight\": 0.01,\n",
      "        \"learning_rate_multiplier\": 0.3\n",
      "      },\n",
      "      \"organization_id\": \"org-6eT84cKNSkcX5WqEyFAc5rPD\",\n",
      "      \"model\": \"davinci\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"object\": \"file\",\n",
      "          \"id\": \"file-HTZ0AJNwHofFiZ695hnIhv80\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"filename\": \"file\",\n",
      "          \"bytes\": 1320,\n",
      "          \"created_at\": 1695721772,\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"validation_files\": [\n",
      "        {\n",
      "          \"object\": \"file\",\n",
      "          \"id\": \"file-yfbAXS0HQIRBxhfCEd0nM768\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"filename\": \"file\",\n",
      "          \"bytes\": 1044,\n",
      "          \"created_at\": 1695721772,\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"result_files\": [\n",
      "        {\n",
      "          \"object\": \"file\",\n",
      "          \"id\": \"file-NtjHvk1WaeWj9iBeMZbynnZt\",\n",
      "          \"purpose\": \"fine-tune-results\",\n",
      "          \"filename\": \"compiled_results.csv\",\n",
      "          \"bytes\": 2802,\n",
      "          \"created_at\": 1695722006,\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"created_at\": 1695721798,\n",
      "      \"updated_at\": 1695722006,\n",
      "      \"status\": \"succeeded\",\n",
      "      \"fine_tuned_model\": \"davinci:ft-hal149-2023-09-26-09-53-25\"\n",
      "    }\n",
      "  ],\n",
      "  \"next_starting_after\": null\n",
      "}\n",
      "davinci:ft-hal149:superhero-2023-09-25-10-24-32\n"
     ]
    }
   ],
   "source": [
    "# Validation of the model\n",
    "# Finally, the fine-tuned model can be retrieved from the “fine_tuned_model” attribute. \n",
    "# The following print statement the name of the final model\n",
    "\n",
    "print(result)\n",
    "\n",
    "# Retrieve the fine-tuned model name from the result\n",
    "fine_tuned_model_name = result[\"data\"][0][\"fine_tuned_model\"]\n",
    "print(fine_tuned_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The square root is a \n",
      "\n",
      "G\n",
      "\n",
      "particular type of root\n",
      "\n",
      "\n",
      "Julius Caesar.\n",
      "\n",
      "b. \n",
      "\n",
      "2. What\n"
     ]
    }
   ],
   "source": [
    "# With this model, we can run queries to validate its results by providing a prompt,\n",
    "# the model name, and creating a query with the openai.Completion.create() function.\n",
    "# The result is retrieved from the answer dictionary as follows:\n",
    "\n",
    "new_prompt = \"\"\" What is the square root of 144?\"\"\" \n",
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model_name,\n",
    "  prompt=new_prompt\n",
    ")\n",
    "\n",
    "print(answer['choices'][0]['text'])\n",
    "\n",
    "new_prompt = \"\"\" Who wrote the play 'Romeo and Juliet'?\"\"\"\n",
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model_name,\n",
    "  prompt=new_prompt\n",
    ")\n",
    "\n",
    "print(answer['choices'][0]['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
