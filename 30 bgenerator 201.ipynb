{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4\n",
      "Response: Lanzaremos 'GreenCharge', una startup de estaciones de carga solares portátiles\n",
      "para vehículos eléctricos. Con un precio unitario de $500, esperamos vender\n",
      "10,000 unidades en el primer año. Invertiremos $100,000 en marketing, con un\n",
      "equipo de 5 personas que costará $250,000 anualmente. - Año 1: Ventas de $5M -\n",
      "$350,000 (gastos generales) = $4.65M de beneficio neto. - Año 2: Estimando un\n",
      "crecimiento del 20%, las ventas serán de $6M. Los gastos generales aumentarán en\n",
      "un 10% a $385,000, dando un beneficio neto de $5.615M. - Año 3: Con otro 20% de\n",
      "crecimiento, las ventas serán de $7.2M. Los gastos generales\n",
      "\n",
      "Model: gpt-3.5-turbo\n",
      "Response: La idea más innovadora y realista para una startup en 2024 es la creación de una\n",
      "plataforma de tecnología de la salud, que ofrezca servicios integrales de\n",
      "atención médica virtual, con un enfoque en la telemedicina y la monitorización\n",
      "remota de pacientes crónicos. El precio unitario del servicio sería de $50 por\n",
      "consulta y se espera realizar 10,000 consultas en el primer año, incrementando\n",
      "un 20% anualmente. Se invertirían $500,000 en marketing durante los primeros 3\n",
      "años. Los costes de personal se estiman en $200,000 al año. Se espera obtener un\n",
      "resultado neto de $500,000 al finalizar el primer año,\n",
      "\n",
      "Model: gpt-3.5-turbo-0301\n",
      "Response: Una idea innovadora y realista para una startup en 2024 podría ser la creación\n",
      "de un servicio de suscripción mensual de alimentos saludables y personalizados.\n",
      "Se utilizaría tecnología de inteligencia artificial para analizar la información\n",
      "del usuario y ofrecer una selección de alimentos personalizada a sus necesidades\n",
      "nutricionales y preferencias. El precio de la suscripción sería de $150 al mes y\n",
      "se esperaría vender al menos 10.000 suscripciones en el primer año. La inversión\n",
      "en marketing sería de $500.000, y los costos de personal incluirían un equipo de\n",
      "20 empleados con un salario promedio de $50,000 al año. Se espera\n",
      "\n",
      "Model: gpt-3.5-turbo-0613\n",
      "Response: Idea de negocio: Una startup que ofrece un servicio de entrega de alimentos\n",
      "saludables y personalizados a través de drones autónomos. Precio unitario del\n",
      "producto: $15 por comida. Ventas esperadas: - Año 1: 10,000 comidas vendidas =\n",
      "$150,000 en ventas. - Año 2: 25,000 comidas vendidas = $375,000 en ventas. - Año\n",
      "3: 50,000 comidas vendidas = $750,000 en ventas. Inversión en marketing: - Año\n",
      "1: $50,000. - Año 2: $75,000. - Año 3: $100,000. Costes de personal: - Año 1: 5\n",
      "empleados (sueldos promedio de $40,000) = $200,000. - Año 2: 10 empleados\n",
      "(sueldos promedio de $45,000) = $450,000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In here we are going to test different models for the same prompt. \n",
    "\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import textwrap\n",
    "\n",
    "# Get the API key\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"Crea en 100 palabras la idea más innovadora pero realista de negocio para una startup que se te ocurra para poner en práctica en 2024. Desglosa el precio unitario del producto, las ventas esperadas, la inversión en marketing, los costes de personal y el resultado neto para los próximos 3 años. \"\n",
    "\n",
    "# Define the list of models\n",
    "models = [\"gpt-4\",\"gpt-3.5-turbo\", \"gpt-3.5-turbo-0301\", \"gpt-3.5-turbo-0613\"]\n",
    "\n",
    "# Maximum number of words for each response\n",
    "max_words = 100\n",
    "\n",
    "# Generate a response for each model\n",
    "for model in models:\n",
    "    try:\n",
    "        # Generate a response with the API\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        # Extract the response text from the API response\n",
    "        generated_response = response['choices'][0]['message']['content']\n",
    "\n",
    "        # Split the response into words\n",
    "        words = generated_response.split()\n",
    "\n",
    "        # Truncate the response to the maximum number of words\n",
    "        truncated_response = ' '.join(words[:max_words])\n",
    "\n",
    "        # Print the response with text wrapping\n",
    "        wrapped_response = textwrap.fill(truncated_response, width=80)  # Adjust the width as needed\n",
    "        print(f\"Model: {model}\\nResponse: {wrapped_response}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error for model {model}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4\n",
      "Response: The equation 2 * (5 * 2) substituting '*' with the exponential operator becomes\n",
      "2 ^ (5 ^ 2). Resolving the operations in brackets first (5 ^ 2 = 25), the\n",
      "equation becomes 2 ^ 25. This is a large number which equals 33,554,432.\n",
      "\n",
      "Model: gpt-3.5-turbo\n",
      "Response: The numeric value of 2 * ( 5 * 2 ) with the exponential operator is 2 ^ ( 5 * 2\n",
      ").\n",
      "\n",
      "Model: gpt-3.5-turbo-0301\n",
      "Response: Assuming you meant the multiplication operator instead of the exponential\n",
      "operator, the numeric value of 2 * (5 * 2) is 20. Here's how to get that result:\n",
      "First, evaluate the expression inside the parentheses: 5 * 2 = 10. Then,\n",
      "substitute that result back into the original expression: 2 * 10 = 20.\n",
      "Therefore, the numeric value of the expression 2 * (5 * 2) is 20.\n",
      "\n",
      "Model: gpt-3.5-turbo-0613\n",
      "Response: The numeric value of 2 * ( 5 * 2 ) when replacing '*' with the exponential\n",
      "operator (^) would be 2^(5^2) which is equal to 2^(25).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In here we are going to test different models for the same prompt. \n",
    "\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import textwrap\n",
    "\n",
    "# Get the API key\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"what is the numeric value of 2 * ( 5 * 2 ) replacing '*' by the exponential operator? \"\n",
    "\n",
    "# Define the list of models\n",
    "models = [\"gpt-4\",\"gpt-3.5-turbo\", \"gpt-3.5-turbo-0301\", \"gpt-3.5-turbo-0613\"]\n",
    "\n",
    "# Maximum number of words for each response\n",
    "max_words = 100\n",
    "\n",
    "# Generate a response for each model\n",
    "for model in models:\n",
    "    try:\n",
    "        # Generate a response with the API\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model, messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        # Extract the response text from the API response\n",
    "        generated_response = response['choices'][0]['message']['content']\n",
    "\n",
    "        # Split the response into words\n",
    "        words = generated_response.split()\n",
    "\n",
    "        # Truncate the response to the maximum number of words\n",
    "        truncated_response = ' '.join(words[:max_words])\n",
    "\n",
    "        # Print the response with text wrapping\n",
    "        wrapped_response = textwrap.fill(truncated_response, width=80)  # Adjust the width as needed\n",
    "        print(f\"Model: {model}\\nResponse: {wrapped_response}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error for model {model}: {e}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
