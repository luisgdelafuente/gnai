{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9iD2LZ8S_Rsk"
      },
      "source": [
        "# Alucinaciones\n",
        "\n",
        "Vamos a someter al modelo a una serie de preguntas relacionadas con las olimpiadas de 2020, con la que no ha sido entrenado. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9xaOcfbRoYo",
        "outputId": "edcc2fc0-7c04-47e9-862f-0c18557908c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\python\\lib\\site-packages (4.32.0)\n",
            "Requirement already satisfied: filelock in c:\\python\\lib\\site-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\python\\lib\\site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\python\\lib\\site-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\luisg\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\python\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\python\\lib\\site-packages (from transformers) (2023.8.8)\n",
            "Requirement already satisfied: requests in c:\\python\\lib\\site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\python\\lib\\site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\python\\lib\\site-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\python\\lib\\site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in c:\\python\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\luisg\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Testing hallucinations . \n",
        "# Instalar las librerías que necesitamos\n",
        "\n",
        "# !pip install openai\n",
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZjHrd5EhRNLD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
          ]
        }
      ],
      "source": [
        "# Importar métodos, API y crear una variable ambiente con el modelo que vamos a usar\n",
        "\n",
        "import openai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from transformers import GPT2TokenizerFast\n",
        "from typing import Dict, Tuple, List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear variable ambiente con el modelo y API \n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "COMPLETIONS_MODEL = \"text-davinci-003\"\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tw-hRjAuP_zW"
      },
      "source": [
        "Ahora hacemos una consulta sobre la que el modelo no haya sido entrenado para que el modelo se invente la respuesta. \n",
        "\n",
        "Marcelo Chierghini es un olimpista brasileño, pero es nadador y quedó en el puesto 8 de las olimpiadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nPMxyKUOSMKQ",
        "outputId": "b65def72-10e0-485f-fdf2-d5f5109ebfe2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Marcelo Chierighini of Brazil won the gold medal in the men's high jump at the 2020 Summer Olympics.\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"Who won the 2020 Summer Olympics men's high jump?\"\n",
        "# prompt = \"Quién ganó las olimpiadas de verano 2020 en la categoría de salto de altura de hombres?\"\n",
        "\n",
        "openai.Completion.create(\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    max_tokens=300,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    model=COMPLETIONS_MODEL\n",
        ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ggF7p2OoNCiV"
      },
      "source": [
        "# Prevenir alucinaciones\n",
        "\n",
        "Vamos a tratar una serie de métodos para prevenir las alucinaciones por este orden: \n",
        "- Hacer reconocer al modelo que no sabe la respuesta (en este notebook)\n",
        "- Mejorar la consulta, es decir el prompt (en este notebook)\n",
        "- Utilizar embeddings.\n",
        "- Fine-tunear el modelo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iicfJAurTe3_",
        "outputId": "ed9c73e5-d12f-4b62-f219-9db219b566b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Lo siento, no lo sé.'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Hacer que el modelo responda que no sabe a respuesta: \n",
        "\n",
        "prompt = \"\"\"Responde a la pregunta lo más verídicamente posible, y si no estás seguro de la respuesta responde 'Lo siento, no lo sé'. \n",
        "\n",
        "Q: Quién ganó las olimpiadas de verano 2020 en la categoría de salto de altura de hombres? \n",
        "A:\"\"\"\n",
        "\n",
        "openai.Completion.create(\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    max_tokens=300,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    model=COMPLETIONS_MODEL\n",
        ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "K68viha-T-18",
        "outputId": "ef3e3fd0-62e2-4823-8225-8afb0ee1b1ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Gianmarco Tamberi and Mutaz Essa Barshim emerged as joint winners of the event.'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mejorar el prompt dando pistas sobre la respuesta, además de lo anterior. \n",
        "# Observar cómo si la cantidad de contexto no es muy grande, podemos incluirla en el prompt directamente. \n",
        "\n",
        "prompt = \"\"\"Answer the question as truthfully as possible using the provided text, and if the answer is not contained within the text below, say \"I don't know\"\n",
        "\n",
        "Context:\n",
        "The men's high jump event at the 2020 Summer Olympics took place between 30 July and 1 August 2021 at the Olympic Stadium.\n",
        "33 athletes from 24 nations competed; the total possible number depended on how many nations would use universality places \n",
        "to enter athletes in addition to the 32 qualifying through mark or ranking (no universality places were used in 2021).\n",
        "Italian athlete Gianmarco Tamberi along with Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following\n",
        "a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal in a rare instance\n",
        "where the athletes of different nations had agreed to share the same medal in the history of Olympics. \n",
        "Barshim in particular was heard to ask a competition official \"Can we have two golds?\" in response to being offered a \n",
        "'jump off'. Maksim Nedasekau of Belarus took bronze. The medals were the first ever in the men's high jump for Italy and \n",
        "Belarus, the first gold in the men's high jump for Italy and Qatar, and the third consecutive medal in the men's high jump\n",
        "for Qatar (all by Barshim). Barshim became only the second man to earn three medals in high jump, joining Patrik Sjöberg\n",
        "of Sweden (1984 to 1992).\n",
        "\n",
        "Q: Who won the 2020 Summer Olympics men's high jump?\n",
        "A:\"\"\"\n",
        "\n",
        "openai.Completion.create(\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    max_tokens=300,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    model=COMPLETIONS_MODEL\n",
        ")[\"choices\"][0][\"text\"].strip(\" \\n\")\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9J6PtaQqOdVh"
      },
      "source": [
        "Haciendo algo de prompt engineering hemos conseguido que el modelo de una respuesta acertada, pero ¿a qué precio? este sistema no es práctico porque no escala: no podemos enviar la totalidad del contexto cada vez que hacemos consultas, y mucho menos el dataset completo cuando éstas son imprevisibles. \n",
        "\n",
        "Aquí es donde tienen sentido los Embeddings. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulating hallucinations with numeric values \n",
        "\n",
        "import requests\n",
        "import os\n",
        "import openai\n",
        "import collections\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Define the prompts and correct answers\n",
        "prompts = [\n",
        "    \"Find the result of 3 plus 6.\",\n",
        "    \"Find the result of 3 plus 6.\",\n",
        "    \"Find the result of 3 plus 6.\",\n",
        "    \"Find the result of 3 plus 6.\",\n",
        "    \"Find the result of 3 plus 6.\"\n",
        "]\n",
        "correct_answer = \"9\"\n",
        "\n",
        "# Number of queries for each prompt\n",
        "num_queries = 25\n",
        "\n",
        "# Initialize responses dictionary\n",
        "responses = {prompt: [] for prompt in prompts}\n",
        "\n",
        "# Send queries and accumulate responses\n",
        "for prompt in prompts:\n",
        "    for _ in range(num_queries):\n",
        "        response = openai.Completion.create(\n",
        "            engine=\"text-davinci-002\",\n",
        "            prompt=prompt,\n",
        "            max_tokens=50,\n",
        "        )\n",
        "        response_text = response.choices[0].text.strip()\n",
        "        responses[prompt].append(response_text)\n",
        "\n",
        "# Calculate statistics for each prompt\n",
        "for prompt, answers in responses.items():\n",
        "    answer_distribution = collections.Counter(answers)\n",
        "    correct_count = answer_distribution[correct_answer]\n",
        "    total_responses = len(answers)\n",
        "    \n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(f\"Correct Answer: '{correct_answer}'\")\n",
        "    print(f\"Correct Count: {correct_count} out of {total_responses} responses\")\n",
        "    print(f\"Accuracy: {correct_count / total_responses:.2%}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOTvzGU2L9W8RwnGD/NvH/0",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
