{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some synthetic data for fine-tuning \n",
    "# We are going to create serveral characters for video games in here: \n",
    "\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define input values\n",
    "ages = ['30', '40', '50']\n",
    "genders = ['man', 'woman']\n",
    "superpowers = ['read in the thoughts', 'turning lead into gold', 'immortality'] \n",
    "\n",
    "# Create an empty list to store results\n",
    "results = []\n",
    "\n",
    "# Loop through input values\n",
    "record_number = 1\n",
    "for age in ages:\n",
    "    for gender in genders:\n",
    "        for power in superpowers:\n",
    "            # Define the prompt with placeholders\n",
    "            prompt = f\"Imagine a complete and detailed description of a {age}-year-old {gender} fictional character who has the superpower of {power}. Write out the entire description in a maximum of 100 words in great detail.\"\n",
    "\n",
    "            # Generate the response using OpenAI's GPT-3 model\n",
    "            response = openai.Completion.create(\n",
    "                model=\"text-davinci-003\",\n",
    "                prompt=prompt,\n",
    "                temperature=0.7,  # Adjust temperature for response creativity\n",
    "                max_tokens=100,  # Limit response to 100 tokens (adjust as needed)\n",
    "                n=1,  # Generate a single response\n",
    "                stop=None,  # Let the model determine when to stop\n",
    "            )\n",
    "\n",
    "            # Extract and store the response text\n",
    "            response_text = response.choices[0].text.strip()\n",
    "\n",
    "            # Create a subprompt string\n",
    "            subprompt = f\"{age}, {gender}, {power}\"\n",
    "\n",
    "            # Store the results in a dictionary\n",
    "            result = {\n",
    "                'record number': record_number,\n",
    "                'age': age,\n",
    "                'gender': gender,\n",
    "                'power': power,\n",
    "                'prompt': prompt,\n",
    "                'subprompt': subprompt,\n",
    "                'response': response_text\n",
    "            }\n",
    "\n",
    "            results.append(result)\n",
    "\n",
    "            # Increment the record number\n",
    "            record_number += 1\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"character_descriptions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['openai', 'api', 'fine_tunes.create', '--training_file', 'prepared_data_prepared.jsonl', '--model', 'davinci', '--suffix', '\"SuperHero\"'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we use the former data to finetune a model \n",
    "\n",
    "import pandas as pd\n",
    "import openai\n",
    "import subprocess\n",
    "\n",
    "# read the previous file with the generated data \n",
    "df = pd.read_csv(\"character_descriptions.csv\")\n",
    "\n",
    "# now we are using the parameters of the prompt (subprompt) as final prompt for the training. \n",
    "prepared_data = df.loc[:,['subprompt','response']]\n",
    "prepared_data.rename(columns={'subprompt':'prompt', 'response':'completion'}, inplace=True)\n",
    "prepared_data.to_csv('prepared_data.csv',index=False)\n",
    "\n",
    "## prepared_data.csv --> prepared_data_prepared.json\n",
    "subprocess.run('openai tools fine_tunes.prepare_data --file prepared_data.csv --quiet'.split())\n",
    "\n",
    "## Start fine-tuning\n",
    "subprocess.run('openai api fine_tunes.create --training_file prepared_data_prepared.jsonl --model davinci --suffix \"SuperHero\"'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Function to retrieve the latest fine-tune job for a model\n",
    "def get_latest_fine_tune_job(model_name):\n",
    "    response = openai.FineTune.list(model=model_name, per_page=1)\n",
    "    if response.data:\n",
    "        return response.data[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to check the status of a fine-tuning job\n",
    "def check_fine_tune_status(fine_tune_id):\n",
    "    response = openai.FineTune.retrieve(fine_tune_id)\n",
    "\n",
    "    # Print relevant information about the fine-tuning job\n",
    "    print(\"Fine-tune ID:\", response.id)\n",
    "    print(\"Status:\", response.status)\n",
    "    print(\"Progress:\", response.progress)\n",
    "\n",
    "    if response.status == \"succeeded\":\n",
    "        print(\"Fine-tuning completed successfully!\")\n",
    "        print(\"Model ID:\", response.model.id)\n",
    "    elif response.status == \"failed\":\n",
    "        print(\"Fine-tuning failed. Check the error details.\")\n",
    "        print(\"Error Details:\", response.error)\n",
    "    else:\n",
    "        print(\"Fine-tuning is still in progress. Check again later.\")\n",
    "\n",
    "    return response.status\n",
    "\n",
    "# Get the latest fine-tuning job for the specified model\n",
    "latest_job = get_latest_fine_tune_job(\"davinci-SuperHero\")  # Update with your model name\n",
    "\n",
    "if latest_job:\n",
    "    fine_tune_id = latest_job.id\n",
    "    print(\"Latest Fine-tune ID:\", fine_tune_id)\n",
    "\n",
    "    # Check fine-tune status every 60 seconds until it is completed or fails\n",
    "    while True:\n",
    "        status = check_fine_tune_status(fine_tune_id)\n",
    "        if status in [\"succeeded\", \"failed\"]:\n",
    "            break\n",
    "        time.sleep(60)  # Sleep for 60 seconds before checking again\n",
    "else:\n",
    "    print(\"No fine-tuning job found for the specified model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Fine-tune ID: ft-2eF6eh6kfyvDneXLWo1knwF5\n",
      "Fine-tune ID: ft-2eF6eh6kfyvDneXLWo1knwF5\n",
      "Status: succeeded\n",
      "Fine-tuning completed successfully!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Check fine-tune status every 60 seconds until it is completed or fails\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     status \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_fine_tune_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfine_tune_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msucceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 25\u001b[0m, in \u001b[0;36mcheck_fine_tune_status\u001b[1;34m(fine_tune_id)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msucceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFine-tuning completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Name:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mname)  \u001b[38;5;66;03m# Get the name of the model\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Function to retrieve the latest fine-tune job for a model\n",
    "def get_latest_fine_tune_job(model_name):\n",
    "    response = openai.FineTune.list(model=model_name, per_page=1)\n",
    "    if response.data:\n",
    "        return response.data[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to check the status of a fine-tuning job\n",
    "def check_fine_tune_status(fine_tune_id):\n",
    "    response = openai.FineTune.retrieve(fine_tune_id)\n",
    "\n",
    "    # Print relevant information about the fine-tuning job\n",
    "    print(\"Fine-tune ID:\", response.id)\n",
    "    print(\"Status:\", response.status)\n",
    "\n",
    "    if response.status == \"succeeded\":\n",
    "        print(\"Fine-tuning completed successfully!\")\n",
    "        print(\"Model ID:\", response.model.id)\n",
    "        print(\"Model Name:\", response.model.name)  # Get the name of the model\n",
    "    elif response.status == \"failed\":\n",
    "        print(\"Fine-tuning failed. Check the error details.\")\n",
    "        print(\"Error Details:\", response.error)\n",
    "    else:\n",
    "        print(\"Fine-tuning is still in progress. Check again later.\")\n",
    "\n",
    "    return response.status\n",
    "\n",
    "# Get the latest fine-tuning job for the specified model\n",
    "latest_job = get_latest_fine_tune_job(\"davinci-SuperHero\")  # Update with your model name\n",
    "\n",
    "if latest_job:\n",
    "    fine_tune_id = latest_job.id\n",
    "    print(\"Latest Fine-tune ID:\", fine_tune_id)\n",
    "\n",
    "    # Check fine-tune status every 60 seconds until it is completed or fails\n",
    "    while True:\n",
    "        status = check_fine_tune_status(fine_tune_id)\n",
    "        if status in [\"succeeded\", \"failed\"]:\n",
    "            break\n",
    "        time.sleep(60)  # Sleep for 60 seconds before checking again\n",
    "else:\n",
    "    print(\"No fine-tuning job found for the specified model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Fine-tune ID: ft-2eF6eh6kfyvDneXLWo1knwF5\n",
      "Fine-tune ID: ft-2eF6eh6kfyvDneXLWo1knwF5\n",
      "Status: succeeded\n",
      "Fine-tuning completed successfully!\n",
      "Model Name: davinci\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Function to retrieve the latest fine-tune job for a model\n",
    "def get_latest_fine_tune_job(model_name):\n",
    "    response = openai.FineTune.list(model=model_name, per_page=1)\n",
    "    if response.data:\n",
    "        return response.data[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to check the status of a fine-tuning job\n",
    "def check_fine_tune_status(fine_tune_id):\n",
    "    response = openai.FineTune.retrieve(fine_tune_id)\n",
    "\n",
    "    # Print relevant information about the fine-tuning job\n",
    "    print(\"Fine-tune ID:\", response.id)\n",
    "    print(\"Status:\", response.status)\n",
    "\n",
    "    if response.status == \"succeeded\":\n",
    "        print(\"Fine-tuning completed successfully!\")\n",
    "        print(\"Model Name:\", response.model)  # Get the name of the model\n",
    "    elif response.status == \"failed\":\n",
    "        print(\"Fine-tuning failed. Check the error details.\")\n",
    "        print(\"Error Details:\", response.error)\n",
    "    else:\n",
    "        print(\"Fine-tuning is still in progress. Check again later.\")\n",
    "\n",
    "    return response.status\n",
    "\n",
    "# Get the latest fine-tuning job for the specified model\n",
    "latest_job = get_latest_fine_tune_job(\"davinci-SuperHero\")  # Update with your model name\n",
    "\n",
    "if latest_job:\n",
    "    fine_tune_id = latest_job.id\n",
    "    print(\"Latest Fine-tune ID:\", fine_tune_id)\n",
    "\n",
    "    # Check fine-tune status every 60 seconds until it is completed or fails\n",
    "    while True:\n",
    "        status = check_fine_tune_status(fine_tune_id)\n",
    "        if status in [\"succeeded\", \"failed\"]:\n",
    "            break\n",
    "        time.sleep(60)  # Sleep for 60 seconds before checking again\n",
    "else:\n",
    "    print(\"No fine-tuning job found for the specified model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This tall, broad-shouldered man has a strong jaw and piercing blue eyes. His dark hair is always perfectly groomed and a hint of stubble is always visible on his strong chin. He wears a black leather jacket over a white shirt and dark jeans. He has a confident air about him, like he can take on the world and win. He has the power of immortality, meaning he will never age or die. He has been around for centuries, watching the world change and evolve. He has seen empires rise and fall, witnessed science and technology become more advanced, and \n"
     ]
    }
   ],
   "source": [
    "# Checking an older model \n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"davinci:ft-hal149:superhero-2023-10-04-09-56-47\",\n",
    "  prompt=\"18, man, inmortality ->\\n\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=500,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=[\"END\"]\n",
    ")\n",
    "\n",
    "text = response[\"choices\"][0][\"text\"]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"davinci:ft-2eF6eh6kfyvDneXLWo1knwF5\",\n",
    "  prompt=\"18, man, inmortality ->\\n\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=500,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=[\"END\"]\n",
    ")\n",
    "\n",
    "text = response[\"choices\"][0][\"text\"]\n",
    "print(text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
